#This module will analyze user thoughts and label them according to the 27 emotions included on Google's goemotion research dataset
#I will utilize the tutorial here https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb to build the model
#I will use files and data from the google-research goemotion respository https://github.com/google-research/google-research/tree/master/goemotions

from transformers import pipeline, AutoTokenizer, TFAutoModelForSequenceClassification #import tools for using FH libraries
import tensorflow

classifier = pipeline("text-classification") #we use api call to access a default pre-trained model

print(classifier("Today is a brand new day")) #we test the model

results = classifier(["I am learning a lot", "This is great"])
for result in results:
    print(result)

#Now lets recreate the pipeline using a pre-trained model and tokenizer
model_name = "bhadresh-savani/distilbert-base-uncased-emotion"
tokenizer = AutoTokenizer.from_pretrained(model_name)
encoding = tokenizer("I am overcoming challenges")
print(encoding)

texts = ["I am overcoming Challenges", "I need to focus if I want to succeed"]

tf_batch = tokenizer(
    texts,
    padding=True, #pad sequences that are too short
    truncation=True, #truncates sequences that are longer than necessary
    max_length=512, 
    return_tensors="tf", #tensors will be generated by TensorFlow
)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
print(tf_model)

tf_outputs = tf_model(tf_batch) #generate outputs

tf_predictions = tensorflow.nn.softmax(tf_outputs.logits, axis=-1) #convert logits to probabilities
print(tf_predictions)

#get highest probability class index
predicted_class_indices = tensorflow.argmax(tf_predictions, axis=-1).numpy()

#get labels from model config
id2label = tf_model.config.id2label #map indices to emotion labels
#config is a json object associated with this model. id2label is a field of this object

#convert indices to actual labels
predicted_labels = [id2label[idx] for idx in predicted_class_indices] #now we associate these labels with the model predictions

# Print the results
for text, label in zip(texts, predicted_labels):
    print(f"Text: {text} â†’ Predicted Emotion: {label}")